{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **数据挖掘——Home Credit Default Risk**\n",
    "\n",
    "Authors：李林（3120220938）、杨洋（3220211141）、敬甲男（3220221052）、李翰杰（3120220936）\n",
    "\n",
    "github地址：https://github.com/leealim/kaggle-Home-Credit-Default-Risk\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "version='v0.1'\n",
    "app_tr_path=\"..\\\\data\\\\home-credit-default-risk\\\\application_train.csv\"\n",
    "app_te_path=\"..\\\\data\\\\home-credit-default-risk\\\\application_test.csv\"\n",
    "\n",
    "app_train = pd.read_csv(app_tr_path)\n",
    "app_test = pd.read_csv(app_te_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COMMONAREA_MEDI</th>\n",
       "      <td>214865</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMMONAREA_AVG</th>\n",
       "      <td>214865</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMMONAREA_MODE</th>\n",
       "      <td>214865</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONLIVINGAPARTMENTS_MODE</th>\n",
       "      <td>213514</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONLIVINGAPARTMENTS_AVG</th>\n",
       "      <td>213514</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Missing Values  % of Total Values\n",
       "COMMONAREA_MEDI                   214865               69.9\n",
       "COMMONAREA_AVG                    214865               69.9\n",
       "COMMONAREA_MODE                   214865               69.9\n",
       "NONLIVINGAPARTMENTS_MODE          213514               69.4\n",
       "NONLIVINGAPARTMENTS_AVG           213514               69.4"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def missing_values_table(df):\n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns.sort_values(\n",
    "    '% of Total Values', ascending=False).round(1)\n",
    "    return mis_val_table_ren_columns\n",
    "\n",
    "missing_values = missing_values_table(app_train)\n",
    "missing_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le_count = 0\n",
    "for col in app_train:\n",
    "    if app_train[col].dtype == 'object':\n",
    "        if len(list(app_train[col].unique())) <= 2:\n",
    "            le.fit(app_train[col])\n",
    "            app_train[col] = le.transform(app_train[col])\n",
    "            app_test[col] = le.transform(app_test[col])\n",
    "            le_count += 1\n",
    "\n",
    "app_train = pd.get_dummies(app_train)\n",
    "app_test = pd.get_dummies(app_test)\n",
    "\n",
    "train_labels = app_train['TARGET']\n",
    "app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)\n",
    "app_train['TARGET'] = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_numeric(df, parent_var, df_name):\n",
    "    \n",
    "    for col in df:\n",
    "        if col != parent_var and 'SK_ID' in col:\n",
    "            df = df.drop(columns = col)\n",
    "            \n",
    "    parent_ids = df[parent_var].copy()\n",
    "    numeric_df = df.select_dtypes('number').copy()\n",
    "    numeric_df[parent_var] = parent_ids\n",
    "    agg = numeric_df.groupby(parent_var).agg(['count', 'mean', 'max', 'min', 'sum'])\n",
    "\n",
    "    columns = []\n",
    "    for var in agg.columns.levels[0]:\n",
    "        if var != parent_var:\n",
    "            for stat in agg.columns.levels[1]:\n",
    "                columns.append('%s_%s_%s' % (df_name, var, stat))\n",
    "    agg.columns = columns\n",
    "    \n",
    "    _, idx = np.unique(agg, axis = 1, return_index=True)\n",
    "    agg = agg.iloc[:, idx]\n",
    "    \n",
    "    return agg\n",
    "\n",
    "def agg_categorical(df, parent_var, df_name):\n",
    "    \n",
    "    categorical = pd.get_dummies(df.select_dtypes('category'))\n",
    "    categorical[parent_var] = df[parent_var]\n",
    "    categorical = categorical.groupby(parent_var).agg(['sum', 'count', 'mean'])\n",
    "    \n",
    "    column_names = []\n",
    "    for var in categorical.columns.levels[0]:\n",
    "        for stat in ['sum', 'count', 'mean']:\n",
    "            column_names.append('%s_%s_%s' % (df_name, var, stat))\n",
    "    categorical.columns = column_names\n",
    "    \n",
    "    _, idx = np.unique(categorical, axis = 1, return_index = True)\n",
    "    categorical = categorical.iloc[:, idx]\n",
    "    \n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kde_target(var_name, df):\n",
    "    \n",
    "    corr = df['TARGET'].corr(df[var_name])\n",
    "    avg_repaid = df.loc[df['TARGET'] == 0, var_name].median()\n",
    "    avg_not_repaid = df.loc[df['TARGET'] == 1, var_name].median()\n",
    "    \n",
    "    plt.figure(figsize = (12, 6))\n",
    "    sns.kdeplot(df.loc[df['TARGET'] == 0, var_name], label = 'TARGET == 0')\n",
    "    sns.kdeplot(df.loc[df['TARGET'] == 1, var_name], label = 'TARGET == 1')\n",
    "\n",
    "    plt.xlabel(var_name); plt.ylabel('Density'); plt.title('%s Distribution' % var_name)\n",
    "    plt.legend() \n",
    "    \n",
    "    print('The correlation between %s and the TARGET is %0.4f' % (var_name, corr))\n",
    "    print('Median value for loan that was not repaid = %0.4f' % avg_not_repaid)\n",
    "    print('Median value for loan that was repaid =     %0.4f' % avg_repaid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def return_size(df):\n",
    "    return round(sys.getsizeof(df) / 1e9, 2)\n",
    "\n",
    "def convert_types(df, print_info = False):\n",
    "    \n",
    "    original_memory = df.memory_usage().sum()\n",
    "    \n",
    "    for c in df:\n",
    "        if ('SK_ID' in c):\n",
    "            df[c] = df[c].fillna(0).astype(np.int32)\n",
    "        elif (df[c].dtype == 'object') and (df[c].nunique() < df.shape[0]):\n",
    "            df[c] = df[c].astype('category')\n",
    "        elif list(df[c].unique()) == [1, 0]:\n",
    "            df[c] = df[c].astype(bool)\n",
    "        elif df[c].dtype == float:\n",
    "            df[c] = df[c].astype(np.float32)\n",
    "        elif df[c].dtype == int:\n",
    "            df[c] = df[c].astype(np.int32)\n",
    "        \n",
    "    new_memory = df.memory_usage().sum()\n",
    "    \n",
    "    if print_info:\n",
    "        print(f'Original Memory Usage: {round(original_memory / 1e9, 2)} gb.')\n",
    "        print(f'New Memory Usage: {round(new_memory / 1e9, 2)} gb.')\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Memory Usage: 0.49 gb.\n",
      "New Memory Usage: 0.18 gb.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2919"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous = pd.read_csv('../data/home-credit-default-risk/previous_application.csv')\n",
    "previous = convert_types(previous, print_info=True)\n",
    "previous_agg = agg_numeric(previous, 'SK_ID_CURR', 'previous')\n",
    "previous_counts = agg_categorical(previous, 'SK_ID_CURR', 'previous')\n",
    "\n",
    "train = app_train\n",
    "train = convert_types(train)\n",
    "test = app_test\n",
    "test = convert_types(test)\n",
    "\n",
    "train = train.merge(previous_counts, on ='SK_ID_CURR', how = 'left')\n",
    "train = train.merge(previous_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "test = test.merge(previous_counts, on ='SK_ID_CURR', how = 'left')\n",
    "test = test.merge(previous_agg, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "gc.enable()\n",
    "del previous, previous_agg, previous_counts\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 605)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 599)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_missing_columns(train, test, threshold = 75):\n",
    "\n",
    "    train_miss = train.isnull().sum()\n",
    "    test_miss = test.isnull().sum()\n",
    "\n",
    "    train_index_list = train_miss.index.tolist()\n",
    "    missing_train_columns=[]\n",
    "    for i in range(train_miss.shape[0]) :\n",
    "        if 100 * train_miss[i] / len(train)>75:\n",
    "            missing_train_columns.append(train_index_list[i])\n",
    "\n",
    "    test_index_list = test_miss.index.tolist()\n",
    "    missing_test_columns=[]\n",
    "    for i in range(test_miss.shape[0]) :\n",
    "        if 100 * test_miss[i] / len(test)>75:\n",
    "            missing_test_columns.append(test_index_list[i])\n",
    "    \n",
    "    missing_columns = list(set(missing_train_columns + missing_test_columns))\n",
    "\n",
    "    train = train.drop(columns = missing_columns)\n",
    "    test = test.drop(columns = missing_columns)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "train, test = remove_missing_columns(train, test)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.9\n",
    "\n",
    "corr_matrix = train.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool_))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "train = train.drop(columns = to_drop)\n",
    "test = test.drop(columns = to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 508)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:52:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"n_estimatores\" } are not used.\n",
      "\n",
      "[[0.9538178  0.04618224]\n",
      " [0.86457473 0.13542528]\n",
      " [0.97555155 0.02444843]\n",
      " ...\n",
      " [0.9697569  0.03024312]\n",
      " [0.9441286  0.05587142]\n",
      " [0.7804461  0.21955387]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import xgboost\n",
    "train_t=train.copy()\n",
    "train_t = train_t.drop(columns = ['TARGET'])\n",
    "x = train_t.values\n",
    "y = train['TARGET'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2 , random_state = 5)\n",
    "model = xgboost.XGBClassifier(n_estimatores = 200, max_depth = 8, subsample = 0.8, colsample_bytree = 0.8, \n",
    "                              min_child_weight = 50, random_state=27).fit(x_train, y_train)\n",
    "#生成train数据放进模型后的答案\n",
    "ans = model.predict_proba(x_test)\n",
    "\n",
    "ans_test = model.predict_proba(test.values)\n",
    "print(ans_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 2)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#生成答案\n",
    "index=test['SK_ID_CURR']\n",
    "ans=pd.DataFrame(ans_test[:,1],columns = ['TARGET'])\n",
    "result=pd.concat([index,ans],axis=1)\n",
    "result.to_csv('../result/'+version+'/submission_t.csv',encoding = 'utf-8',index = 0)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_te = pd.read_csv(app_te_path)\n",
    "\n",
    "t = missing_values_table(app_te, \"application_{train|test}.csv\")\n",
    "t_small=t.loc[t[\"% of Total Values\"]<3]\n",
    "t_large=t.loc[t[\"% of Total Values\"]>3]\n",
    "app_te.dropna(subset=t_small[\"Row\"],\n",
    "          axis=0, # axis=0表示删除行；\n",
    "          how='any', # how=any表示若列name、age中，任意一个出现空值，就删掉该行\n",
    "          inplace=True # inplace=True表示在原df上进行修改；\n",
    "          )\n",
    "app_te = app_te.reset_index(drop=True)\n",
    "\n",
    "t = missing_values_table(app_te, \"application_{train|test}.csv\")\n",
    "temp=t.drop(columns=[\"Special\"]).isnull().T.any()\n",
    "temp.loc[temp==True].index\n",
    "rows=t.loc[temp.loc[temp==True].index].Row\n",
    "for col in rows: \n",
    "    app_te[str(col)] = app_te[str(col)].fillna(value=\"MyNull\")\n",
    "\n",
    "t = missing_values_table(app_te, \"application_{train|test}.csv\")\n",
    "t_house=t.loc[t[\"Description\"]==\"Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor\"]\n",
    "temp=app_te.loc[:,t_house[\"Row\"].tolist()].isnull().sum(axis=1)\n",
    "app_te[\"MY_HOUSE_OWN\"]=temp\n",
    "app_te_drop_list=t_house[\"Row\"].tolist()\n",
    "for col in app_te_drop_list: \n",
    "    app_te[col] = app_te[col].fillna(value=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
